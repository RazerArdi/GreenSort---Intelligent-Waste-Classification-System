{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c899fa6",
   "metadata": {},
   "source": [
    "# Laporan Proyek Machine Learning - SistemRekomendasi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c03604",
   "metadata": {},
   "source": [
    "## Domain Proyek\n",
    "\n",
    "Pada proyek ini, kita membahas masalah pengelolaan sampah dan memberikan solusi berbasis machine learning untuk memberikan rekomendasi pengelolaan sampah yang lebih tepat. Pengelolaan sampah yang efisien sangat penting untuk mengurangi dampak negatif terhadap lingkungan, terutama dengan meningkatnya volume sampah. Pentingnya pengelolaan sampah yang tepat tidak hanya membantu mengurangi pencemaran tetapi juga mengurangi penggunaan sumber daya alam. Oleh karena itu, pengelolaan yang efisien sangat dibutuhkan agar dapat mengoptimalkan proses daur ulang, komposting, dan pembuangan sampah."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94ca1ba",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba31d18",
   "metadata": {},
   "source": [
    "### Problem Statements\n",
    "\n",
    "- Bagaimana memberikan rekomendasi pengelolaan sampah yang tepat berdasarkan jenis sampah?\n",
    "- Bagaimana membangun model machine learning yang dapat memprediksi pengelolaan sampah yang optimal berdasarkan jenisnya?\n",
    "\n",
    "### Goals\n",
    "\n",
    "- Memberikan rekomendasi pengelolaan sampah yang tepat untuk jenis sampah yang diberikan.\n",
    "- Membangun model prediktif menggunakan machine learning yang dapat memberikan rekomendasi pengelolaan secara otomatis dan efisien.\n",
    "\n",
    "### Solution Statements\n",
    "\n",
    "- Menggunakan model neural network untuk memprediksi rekomendasi pengelolaan berdasarkan jenis sampah.\n",
    "- Meningkatkan akurasi model dengan melakukan pengoptimalan hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60c2c4b",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "Dataset yang digunakan berisi informasi mengenai jenis sampah dan rekomendasi pengelolaan terkait. Dataset ini dapat diunduh dari sumber internal atau dibuat berdasarkan pengetahuan yang ada.\n",
    "\n",
    "### Variabel pada dataset:\n",
    "- **Jenis_Sampah**: Jenis sampah (misal: Kardus, Plastik, Kertas, dll.)\n",
    "- **Rekomendasi**: Rekomendasi pengelolaan untuk setiap jenis sampah (misal: Daur ulang, Komposkan, dll.)\n",
    "- **Edukasi**: Penjelasan mengenai manfaat pengelolaan sampah yang tepat.\n",
    "- **Dampak_Lingkungan**: Dampak negatif dari pengelolaan yang salah.\n",
    "- **Proses_Pengolahan**: Cara-cara pengolahan atau daur ulang sampah tersebut."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f79b43",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Dalam tahap ini, data yang kita gunakan perlu dipersiapkan agar bisa digunakan oleh model machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df68af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa60aadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "data = {\n",
    "    'Jenis_Sampah': ['Cardboard', 'Food Organics', 'Glass', 'Metal',\n",
    "                     'Miscellaneous Trash', 'Paper', 'Plastic',\n",
    "                     'Textile Trash', 'Vegetation'],\n",
    "    'Rekomendasi': ['Daur ulang', 'Komposkan', 'Daur ulang', 'Jual ke pengepul',\n",
    "                    'Buang ke TPS B3', 'Daur ulang', 'Daur ulang', 'Daur ulang', 'Komposkan'],\n",
    "    'Edukasi': [\n",
    "        'Daur ulang kardus membantu mengurangi sampah dan menghemat sumber daya alam.',\n",
    "        'Sampah organik dapat dijadikan pupuk kompos untuk pertanian.',\n",
    "        'Daur ulang kaca menghemat energi dan mengurangi polusi.',\n",
    "        'Logam bekas bisa dijual ke pengepul dan didaur ulang.',\n",
    "        'Sampah misc. harus dibuang sesuai dengan jenisnya ke tempat sampah yang tepat.',\n",
    "        'Daur ulang kertas mengurangi penggunaan pohon dan membantu kelestarian lingkungan.',\n",
    "        'Daur ulang plastik membantu mengurangi sampah plastik di lingkungan.',\n",
    "        'Daur ulang tekstil mengurangi limbah dan dapat digunakan untuk pembuatan produk baru.',\n",
    "        'Komposkan sampah vegetasi untuk menghasilkan pupuk alami.'\n",
    "    ],\n",
    "    'Dampak_Lingkungan': [\n",
    "        'Sampah kardus yang tidak didaur ulang dapat menambah volume sampah di TPA.',\n",
    "        'Daur ulang sampah organik mengurangi volume sampah di TPA.',\n",
    "        'Daur ulang kaca mengurangi polusi dan konsumsi energi dalam produksi kaca baru.',\n",
    "        'Daur ulang logam mengurangi penggunaan sumber daya alam dan mengurangi polusi.',\n",
    "        'Sampah yang tidak dikelola dengan baik dapat mencemari tanah dan air.',\n",
    "        'Daur ulang kertas mengurangi penebangan pohon dan mengurangi polusi.',\n",
    "        'Sampah plastik yang tidak didaur ulang dapat mencemari lingkungan dan laut.',\n",
    "        'Daur ulang tekstil dapat mengurangi limbah dan membantu meminimalisir dampak industri tekstil.',\n",
    "        'Kompos organik membantu menghasilkan pupuk yang ramah lingkungan.'\n",
    "    ],\n",
    "    'Proses_Pengolahan': [\n",
    "        'Kardus dipilah dan dihancurkan untuk didaur ulang menjadi produk baru.',\n",
    "        'Sampah organik dikomposkan dan digunakan untuk pertanian.',\n",
    "        'Kaca diproses melalui daur ulang untuk digunakan kembali dalam produksi kaca baru.',\n",
    "        'Logam diproses dengan cara dilebur untuk menghasilkan produk baru.',\n",
    "        'Sampah misc. diproses sesuai dengan jenisnya melalui tempat sampah yang sesuai.',\n",
    "        'Kertas didaur ulang menjadi kertas baru yang dapat digunakan kembali.',\n",
    "        'Plastik dipilah, dihancurkan, dan diproses menjadi bahan baku plastik baru.',\n",
    "        'Tekstil didaur ulang menjadi produk baru seperti tas atau bahan tekstil lainnya.',\n",
    "        'Sampah vegetasi dikomposkan untuk menghasilkan pupuk organik.'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Encode labels\n",
    "le_jenis_sampah = LabelEncoder()\n",
    "le_rekomendasi = LabelEncoder()\n",
    "df['Jenis_Sampah_Encoded'] = le_jenis_sampah.fit_transform(df['Jenis_Sampah'])\n",
    "df['Rekomendasi_Encoded'] = le_rekomendasi.fit_transform(df['Rekomendasi'])\n",
    "\n",
    "# Pisahkan fitur dan target\n",
    "X = df['Jenis_Sampah_Encoded'].values.reshape(-1, 1)\n",
    "y = df['Rekomendasi_Encoded'].values\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5039adf5",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Pada tahap ini, kita membangun model neural network untuk memprediksi rekomendasi pengelolaan berdasarkan jenis sampah. Model ini terdiri dari beberapa layer dengan fungsi aktivasi ReLU dan output softmax untuk klasifikasi multi-kelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "db888dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bayuardiyansyah/anaconda3/envs/py310/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.3556 - loss: 1.8113 - val_accuracy: 0.5000 - val_loss: 1.1725\n",
      "Epoch 2/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3556 - loss: 1.3308 - val_accuracy: 0.5000 - val_loss: 1.3302\n",
      "Epoch 3/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2722 - loss: 1.5108 - val_accuracy: 0.5000 - val_loss: 1.5073\n",
      "Epoch 4/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4806 - loss: 1.2049 - val_accuracy: 0.5000 - val_loss: 1.7168\n",
      "Epoch 5/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2472 - loss: 1.1667 - val_accuracy: 0.5000 - val_loss: 1.9309\n",
      "Epoch 6/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4139 - loss: 1.1218 - val_accuracy: 0.5000 - val_loss: 2.0677\n",
      "Epoch 7/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5778 - loss: 1.1490 - val_accuracy: 0.0000e+00 - val_loss: 2.2058\n",
      "Epoch 8/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5778 - loss: 1.0073 - val_accuracy: 0.0000e+00 - val_loss: 2.3230\n",
      "Epoch 9/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6611 - loss: 1.0812 - val_accuracy: 0.0000e+00 - val_loss: 2.3939\n",
      "Epoch 10/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6611 - loss: 1.0211 - val_accuracy: 0.0000e+00 - val_loss: 2.4738\n",
      "Epoch 11/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4111 - loss: 1.0410 - val_accuracy: 0.0000e+00 - val_loss: 2.5087\n",
      "Epoch 12/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7278 - loss: 1.1138 - val_accuracy: 0.5000 - val_loss: 2.4984\n",
      "Epoch 13/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6861 - loss: 1.0924 - val_accuracy: 0.5000 - val_loss: 2.5096\n",
      "Epoch 14/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3389 - loss: 1.1451 - val_accuracy: 0.5000 - val_loss: 2.5940\n",
      "Epoch 15/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8250 - loss: 1.0151 - val_accuracy: 0.5000 - val_loss: 2.5980\n",
      "Epoch 16/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7278 - loss: 0.9520 - val_accuracy: 0.5000 - val_loss: 2.6510\n",
      "Epoch 17/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5889 - loss: 0.9835 - val_accuracy: 0.0000e+00 - val_loss: 2.7501\n",
      "Epoch 18/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7528 - loss: 1.0667 - val_accuracy: 0.0000e+00 - val_loss: 2.8340\n",
      "Epoch 19/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9333 - loss: 0.8998 - val_accuracy: 0.0000e+00 - val_loss: 2.8820\n",
      "Epoch 20/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9333 - loss: 0.9179 - val_accuracy: 0.0000e+00 - val_loss: 2.8952\n",
      "Epoch 21/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7528 - loss: 1.0163 - val_accuracy: 0.5000 - val_loss: 2.9118\n",
      "Epoch 22/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9333 - loss: 0.8913 - val_accuracy: 0.0000e+00 - val_loss: 2.9978\n",
      "Epoch 23/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5861 - loss: 1.1112 - val_accuracy: 0.5000 - val_loss: 3.0333\n",
      "Epoch 24/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9333 - loss: 0.8740 - val_accuracy: 0.5000 - val_loss: 3.0593\n",
      "Epoch 25/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5861 - loss: 1.0862 - val_accuracy: 0.0000e+00 - val_loss: 3.1390\n",
      "Epoch 26/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5861 - loss: 1.0591 - val_accuracy: 0.0000e+00 - val_loss: 3.2280\n",
      "Epoch 27/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9333 - loss: 0.8152 - val_accuracy: 0.0000e+00 - val_loss: 3.2559\n",
      "Epoch 28/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9333 - loss: 0.8017 - val_accuracy: 0.0000e+00 - val_loss: 3.2989\n",
      "Epoch 29/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7528 - loss: 0.9405 - val_accuracy: 0.0000e+00 - val_loss: 3.3182\n",
      "Epoch 30/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8917 - loss: 0.7960 - val_accuracy: 0.0000e+00 - val_loss: 3.3944\n",
      "Epoch 31/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9333 - loss: 0.7435 - val_accuracy: 0.0000e+00 - val_loss: 3.4355\n",
      "Epoch 32/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9333 - loss: 0.7555 - val_accuracy: 0.0000e+00 - val_loss: 3.4440\n",
      "Epoch 33/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7528 - loss: 0.9496 - val_accuracy: 0.5000 - val_loss: 3.4373\n",
      "Epoch 34/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9333 - loss: 0.7703 - val_accuracy: 0.5000 - val_loss: 3.4622\n",
      "Epoch 35/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5861 - loss: 1.0168 - val_accuracy: 0.5000 - val_loss: 3.5335\n",
      "Epoch 36/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5861 - loss: 1.0189 - val_accuracy: 0.0000e+00 - val_loss: 3.6432\n",
      "Epoch 37/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8361 - loss: 0.7704 - val_accuracy: 0.0000e+00 - val_loss: 3.6699\n",
      "Epoch 38/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8917 - loss: 0.7491 - val_accuracy: 0.5000 - val_loss: 3.6754\n",
      "Epoch 39/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5861 - loss: 1.0150 - val_accuracy: 0.0000e+00 - val_loss: 3.7603\n",
      "Epoch 40/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8361 - loss: 0.7641 - val_accuracy: 0.0000e+00 - val_loss: 3.8062\n",
      "Epoch 41/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8917 - loss: 0.6831 - val_accuracy: 0.0000e+00 - val_loss: 3.8439\n",
      "Epoch 42/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9333 - loss: 0.7442 - val_accuracy: 0.0000e+00 - val_loss: 3.8320\n",
      "Epoch 43/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8917 - loss: 0.7186 - val_accuracy: 0.0000e+00 - val_loss: 3.8465\n",
      "Epoch 44/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9333 - loss: 0.6573 - val_accuracy: 0.5000 - val_loss: 3.8638\n",
      "Epoch 45/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7528 - loss: 0.8899 - val_accuracy: 0.0000e+00 - val_loss: 3.9305\n",
      "Epoch 46/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9333 - loss: 0.6995 - val_accuracy: 0.0000e+00 - val_loss: 3.9533\n",
      "Epoch 47/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9333 - loss: 0.6329 - val_accuracy: 0.0000e+00 - val_loss: 4.0151\n",
      "Epoch 48/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8917 - loss: 0.6121 - val_accuracy: 0.0000e+00 - val_loss: 4.1037\n",
      "Epoch 49/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5861 - loss: 0.9562 - val_accuracy: 0.0000e+00 - val_loss: 4.1718\n",
      "Epoch 50/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5861 - loss: 0.9073 - val_accuracy: 0.0000e+00 - val_loss: 4.2295\n"
     ]
    }
   ],
   "source": [
    "# Membangun model neural network yang lebih sederhana\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_shape=(1,), activation='relu'))  # Lapisan sederhana\n",
    "model.add(Dense(len(le_rekomendasi.classes_), activation='softmax'))  # Output layer\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=0.01),  # Learning rate lebih besar\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Latih model dengan lebih sedikit epoch\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=1, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a4022c",
   "metadata": {},
   "source": [
    "### valuation\n",
    "\n",
    "Pada bagian ini, kita akan mengevaluasi hasil model menggunakan metrik akurasi untuk mengukur seberapa baik model kita dalam memprediksi jenis sampah dan memberikan rekomendasi pengelolaan yang tepat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a7399ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi model: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Evaluasi model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Akurasi model: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7619ba",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee593afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f6bf7630940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Jenis Sampah: Plastic\n",
      "Rekomendasi Pengelolaan: Komposkan\n",
      "Edukasi: Daur ulang plastik membantu mengurangi sampah plastik di lingkungan.\n",
      "Dampak Lingkungan: Sampah plastik yang tidak didaur ulang dapat mencemari lingkungan dan laut.\n",
      "Proses Pengolahan: Plastik dipilah, dihancurkan, dan diproses menjadi bahan baku plastik baru.\n",
      "--------------------------------------------------\n",
      "Jenis Sampah: Paper\n",
      "Rekomendasi Pengelolaan: Daur ulang\n",
      "Edukasi: Daur ulang kertas mengurangi penggunaan pohon dan membantu kelestarian lingkungan.\n",
      "Dampak Lingkungan: Daur ulang kertas mengurangi penebangan pohon dan mengurangi polusi.\n",
      "Proses Pengolahan: Kertas didaur ulang menjadi kertas baru yang dapat digunakan kembali.\n",
      "--------------------------------------------------\n",
      "Jenis Sampah: Vegetation\n",
      "Rekomendasi Pengelolaan: Komposkan\n",
      "Edukasi: Komposkan sampah vegetasi untuk menghasilkan pupuk alami.\n",
      "Dampak Lingkungan: Kompos organik membantu menghasilkan pupuk yang ramah lingkungan.\n",
      "Proses Pengolahan: Sampah vegetasi dikomposkan untuk menghasilkan pupuk organik.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Fungsi untuk memprediksi rekomendasi\n",
    "def predict_rekomendasi(jenis_sampah):\n",
    "    try:\n",
    "        jenis_sampah_encoded = le_jenis_sampah.transform([jenis_sampah])[0]\n",
    "        prediksi = model.predict(np.array([[jenis_sampah_encoded]]), verbose=0)\n",
    "        rekomendasi_encoded = np.argmax(prediksi)\n",
    "        rekomendasi = le_rekomendasi.inverse_transform([rekomendasi_encoded])[0]\n",
    "        \n",
    "        print(f\"Jenis Sampah: {jenis_sampah}\")\n",
    "        print(f\"Rekomendasi Pengelolaan: {rekomendasi}\")\n",
    "        sampah_info = df[df['Jenis_Sampah'] == jenis_sampah].iloc[0]\n",
    "        print(f\"Edukasi: {sampah_info['Edukasi']}\")\n",
    "        print(f\"Dampak Lingkungan: {sampah_info['Dampak_Lingkungan']}\")\n",
    "        print(f\"Proses Pengolahan: {sampah_info['Proses_Pengolahan']}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(f\"Jenis sampah '{jenis_sampah}' tidak dikenali dalam dataset.\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Tes prediksi\n",
    "predict_rekomendasi(\"Plastic\")\n",
    "predict_rekomendasi(\"Paper\")\n",
    "predict_rekomendasi(\"Vegetation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3e0f4695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jenis Sampah: Textile Trash\n",
      "Rekomendasi Pengelolaan: Komposkan\n",
      "Edukasi: Daur ulang tekstil mengurangi limbah dan dapat digunakan untuk pembuatan produk baru.\n",
      "Dampak Lingkungan: Daur ulang tekstil dapat mengurangi limbah dan membantu meminimalisir dampak industri tekstil.\n",
      "Proses Pengolahan: Tekstil didaur ulang menjadi produk baru seperti tas atau bahan tekstil lainnya.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "predict_rekomendasi(\"Textile Trash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cefd3f",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bcb1b4a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflowjs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflowjs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtfjs\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Simpan model dalam format Keras (.h5)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/models/RekomendasiSampah/sampah_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, include_optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflowjs'"
     ]
    }
   ],
   "source": [
    "import tensorflowjs as tfjs\n",
    "\n",
    "# Simpan model dalam format Keras (.h5)\n",
    "model.save('/models/RekomendasiSampah/sampah_model.h5', include_optimizer=False)\n",
    "\n",
    "# Konversi ke format TensorFlow.js\n",
    "tfjs.converters.save_keras_model(model, '/models/RekomendasiSampah/tfjs_sampah_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
