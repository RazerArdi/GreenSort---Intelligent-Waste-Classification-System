{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c899fa6",
   "metadata": {},
   "source": [
    "# Laporan Proyek Machine Learning - SistemRekomendasi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3655e8ea",
   "metadata": {},
   "source": [
    "## Pendahuluan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947ee6ac",
   "metadata": {},
   "source": [
    "Sistem rekomendasi daur ulang sampah dirancang untuk membantu pengguna dalam mengelola sampah dengan memberikan saran daur ulang yang sesuai berdasarkan jenis sampah dan beratnya. Sistem ini menggunakan pendekatan berbasis teks dengan TF-IDF Vectorizer dan cosine similarity untuk mencocokkan deskripsi sampah pengguna dengan rekomendasi dalam dataset, serta mempertimbangkan rentang berat sampah dalam satuan kilogram. Tujuan utama adalah mempromosikan pengelolaan sampah yang ramah lingkungan dengan rekomendasi yang praktis dan spesifik."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f435bbc2",
   "metadata": {},
   "source": [
    "## Metodologi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65f4f3e",
   "metadata": {},
   "source": [
    "Dataset\n",
    "\n",
    "Dataset digunakan dalam format JSON (dataset_rekomendasi_daur_ulang_berat_lebih_lebar.json) dan berisi beberapa entri untuk setiap kategori sampah, seperti Kardus, Plastik, dan Vegetasi. Setiap entri memiliki:\n",
    "\n",
    "1. `kategori`: Nama kategori sampah (misalnya, Plastik, Kertas).\n",
    "2. `berat_min_kg`: Berat minimum dalam kilogram.\n",
    "3. `berat_max_kg`: Berat maksimum dalam kilogram.\n",
    "\n",
    "rekomendasi: Daftar saran daur ulang yang relevan dengan rentang berat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2686ca",
   "metadata": {},
   "source": [
    "Contoh struktur dataset:\n",
    "\n",
    "```[\n",
    "    {\n",
    "        \"kategori\": \"Plastik\",\n",
    "        \"berat_min_kg\": 0.01,\n",
    "        \"berat_max_kg\": 0.5,\n",
    "        \"rekomendasi\": [\n",
    "            \"Cuci kantong plastik atau botol kecil sebelum didaur ulang.\",\n",
    "            \"Gunakan kembali kantong plastik untuk keperluan rumah tangga.\",\n",
    "            \"Buang plastik ringan ke tempat pengumpulan plastik di bank sampah.\"\n",
    "        ]\n",
    "    },\n",
    "    .....\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "309dfa4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 17:47:19.120694: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-18 17:47:19.157383: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-18 17:47:19.157419: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-18 17:47:19.159442: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-18 17:47:19.168489: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-18 17:47:19.977080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "836e089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "try:\n",
    "    with open(\"../data/rekomendasi/dataset_rekomendasi_daur_ulang.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File dataset tidak ditemukan.\")\n",
    "    exit(1)\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Error: Format JSON tidak valid.\")\n",
    "    exit(1)\n",
    "\n",
    "# Konversi data menjadi DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Gabungkan rekomendasi menjadi satu kolom untuk vektorisasi\n",
    "df['combined_rekomendasi'] = df['rekomendasi'].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84e45fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kategori</th>\n",
       "      <th>berat_min_kg</th>\n",
       "      <th>berat_max_kg</th>\n",
       "      <th>rekomendasi</th>\n",
       "      <th>combined_rekomendasi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kardus</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Lipat kardus kecil seperti kotak sepatu untuk...</td>\n",
       "      <td>Lipat kardus kecil seperti kotak sepatu untuk ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kardus</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[Potong kardus besar menjadi bagian kecil untu...</td>\n",
       "      <td>Potong kardus besar menjadi bagian kecil untuk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kardus</td>\n",
       "      <td>10.00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>[Jual ke pengepul kardus untuk daur ulang skal...</td>\n",
       "      <td>Jual ke pengepul kardus untuk daur ulang skala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kardus</td>\n",
       "      <td>30.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[Hubungi pabrik daur ulang kertas untuk pengam...</td>\n",
       "      <td>Hubungi pabrik daur ulang kertas untuk pengamb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bahan Organik Makanan</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Kompos sisa makanan harian seperti kulit sayu...</td>\n",
       "      <td>Kompos sisa makanan harian seperti kulit sayur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                kategori  berat_min_kg  berat_max_kg  \\\n",
       "0                 Kardus          0.10           1.0   \n",
       "1                 Kardus          1.00          10.0   \n",
       "2                 Kardus         10.00          30.0   \n",
       "3                 Kardus         30.00         100.0   \n",
       "4  Bahan Organik Makanan          0.05           1.0   \n",
       "\n",
       "                                         rekomendasi  \\\n",
       "0  [Lipat kardus kecil seperti kotak sepatu untuk...   \n",
       "1  [Potong kardus besar menjadi bagian kecil untu...   \n",
       "2  [Jual ke pengepul kardus untuk daur ulang skal...   \n",
       "3  [Hubungi pabrik daur ulang kertas untuk pengam...   \n",
       "4  [Kompos sisa makanan harian seperti kulit sayu...   \n",
       "\n",
       "                                combined_rekomendasi  \n",
       "0  Lipat kardus kecil seperti kotak sepatu untuk ...  \n",
       "1  Potong kardus besar menjadi bagian kecil untuk...  \n",
       "2  Jual ke pengepul kardus untuk daur ulang skala...  \n",
       "3  Hubungi pabrik daur ulang kertas untuk pengamb...  \n",
       "4  Kompos sisa makanan harian seperti kulit sayur...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dfd8f3",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73c88d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 17:47:21.351142: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-18 17:47:21.451032: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "texts = df['combined_rekomendasi'].values  # Teks rekomendasi\n",
    "labels = np.arange(len(texts))  # Indeks sebagai label (untuk mencocokkan entri)\n",
    "\n",
    "# lapisan vektorisasi teks\n",
    "max_tokens = 1000  # Jumlah kata unik maksimum\n",
    "\n",
    "text_vectorizer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode='tf_idf'  # Menggunakan TF-IDF\n",
    ")\n",
    "\n",
    "# Adapt vectorizer ke data teks\n",
    "text_vectorizer.adapt(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7500a1",
   "metadata": {},
   "source": [
    "## modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eabf7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "outputs = x  # Output adalah vektor TF-IDF\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.compile(optimizer='adam', loss='mse')  # Loss tidak terlalu relevan karena ini bukan pelatihan supervised\n",
    "\n",
    "# 5. Fungsi untuk mendapatkan rekomendasi\n",
    "def get_recommendation(model, input_kategori, input_berat_kg, df, tolerance=0.2):\n",
    "    # Cari kategori dalam dataset untuk kecocokan teks\n",
    "    matching_rows = df[df['kategori'] == input_kategori]\n",
    "    if matching_rows.empty:\n",
    "        return {\"message\": \"Kategori tidak ditemukan dalam dataset.\"}\n",
    "\n",
    "    # Vektorisasi input teks (kategori) - pastikan input kategori adalah string, bukan list\n",
    "    # FIX: Make sure input_kategori is passed as a single element array of strings\n",
    "    input_vec = model.predict(np.array([input_kategori]))[0]\n",
    "    \n",
    "    # Vektorisasi semua teks rekomendasi dalam dataset\n",
    "    # FIX: Convert to numpy array to ensure consistent handling\n",
    "    rekomendasi_texts = matching_rows['combined_rekomendasi'].values\n",
    "    dataset_vecs = model.predict(np.array(rekomendasi_texts))\n",
    "    \n",
    "    # Hitung cosine similarity\n",
    "    cosine_sim = np.dot(dataset_vecs, input_vec) / (np.linalg.norm(dataset_vecs, axis=1) * np.linalg.norm(input_vec))\n",
    "    \n",
    "    # Ambil indeks dengan skor tertinggi\n",
    "    best_match_idx = np.argmax(cosine_sim)\n",
    "    \n",
    "    # Dapatkan data dari entri terbaik\n",
    "    kategori = matching_rows.iloc[best_match_idx]['kategori']\n",
    "    rekomendasi_list = matching_rows.iloc[best_match_idx]['rekomendasi']\n",
    "    berat_min_kg = matching_rows.iloc[best_match_idx]['berat_min_kg']\n",
    "    berat_max_kg = matching_rows.iloc[best_match_idx]['berat_max_kg']\n",
    "    \n",
    "    # Periksa rentang berat\n",
    "    min_tolerant = berat_min_kg * (1 - tolerance)\n",
    "    max_tolerant = berat_max_kg * (1 + tolerance)\n",
    "    \n",
    "    if min_tolerant <= input_berat_kg <= max_tolerant:\n",
    "        message = \"\"\n",
    "    else:\n",
    "        message = (\n",
    "            f\"Berat sampah Anda ({input_berat_kg} kg) sedikit tidak sesuai dengan rekomendasi \"\n",
    "            f\"untuk kategori ini ({berat_min_kg} kg - {berat_max_kg} kg).\\n\\n\"\n",
    "            \"Namun, berikut adalah beberapa rekomendasi yang bisa diterapkan:\\n\"\n",
    "        )\n",
    "    \n",
    "    return {\n",
    "        \"kategori\": kategori,\n",
    "        \"berat_input_kg\": input_berat_kg,\n",
    "        \"berat_min_kg\": berat_min_kg,\n",
    "        \"berat_max_kg\": berat_max_kg,\n",
    "        \"message\": message,\n",
    "        \"rekomendasi\": rekomendasi_list\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdb7eef",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a63c904",
   "metadata": {},
   "source": [
    "Azure MLFlows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "232a6e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model berhasil disimpan di folder 'Sistemrekomendasi/models/recycling_recommendation_model.keras'\n",
      "Dataset disimpan sebagai 'dataset.json'\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp4y95gdi_/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp4y95gdi_/model/data/model/assets\n",
      "Registered model 'Recycling_Recommendation_Model' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dan dataset berhasil disimpan ke MLflow di /mnt/d/PROJECT/CapstoneProjectDBSteam/mlruns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'Recycling_Recommendation_Model'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from mlflow.models.signature import infer_signature\n",
    "import os\n",
    "\n",
    "# Load Dataset\n",
    "try:\n",
    "    with open(\"../data/rekomendasi/dataset_rekomendasi_daur_ulang.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File dataset tidak ditemukan.\")\n",
    "    exit(1)\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Error: Format JSON tidak valid.\")\n",
    "    exit(1)\n",
    "\n",
    "# Konversi data menjadi DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Gabungkan rekomendasi menjadi satu kolom untuk vektorisasi\n",
    "df['combined_rekomendasi'] = df['rekomendasi'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "texts = df['combined_rekomendasi'].values  # Teks rekomendasi\n",
    "labels = np.arange(len(texts))  # Indeks sebagai label (untuk mencocokkan entri)\n",
    "\n",
    "# Lapisan vektorisasi teks\n",
    "max_tokens = 1000  # Jumlah kata unik maksimum\n",
    "\n",
    "text_vectorizer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode='tf_idf'  # Menggunakan TF-IDF\n",
    ")\n",
    "\n",
    "# Adapt vectorizer ke data teks\n",
    "text_vectorizer.adapt(texts)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "outputs = x  # Output adalah vektor TF-IDF\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.compile(optimizer='adam', loss='mse')  # Loss tidak terlalu relevan karena ini bukan pelatihan supervised\n",
    "\n",
    "# Fungsi untuk mendapatkan rekomendasi\n",
    "def get_recommendation(model, input_kategori, input_berat_kg, df, tolerance=0.2):\n",
    "    matching_rows = df[df['kategori'] == input_kategori]\n",
    "    if matching_rows.empty:\n",
    "        return {\"message\": \"Kategori tidak ditemukan dalam dataset.\"}\n",
    "\n",
    "    input_vec = model.predict(np.array([input_kategori]))[0]\n",
    "    rekomendasi_texts = matching_rows['combined_rekomendasi'].values\n",
    "    dataset_vecs = model.predict(np.array(rekomendasi_texts))\n",
    "    \n",
    "    cosine_sim = np.dot(dataset_vecs, input_vec) / (np.linalg.norm(dataset_vecs, axis=1) * np.linalg.norm(input_vec))\n",
    "    best_match_idx = np.argmax(cosine_sim)\n",
    "    \n",
    "    kategori = matching_rows.iloc[best_match_idx]['kategori']\n",
    "    rekomendasi_list = matching_rows.iloc[best_match_idx]['rekomendasi']\n",
    "    berat_min_kg = matching_rows.iloc[best_match_idx]['berat_min_kg']\n",
    "    berat_max_kg = matching_rows.iloc[best_match_idx]['berat_max_kg']\n",
    "    \n",
    "    min_tolerant = berat_min_kg * (1 - tolerance)\n",
    "    max_tolerant = berat_max_kg * (1 + tolerance)\n",
    "    \n",
    "    if min_tolerant <= input_berat_kg <= max_tolerant:\n",
    "        message = \"\"\n",
    "    else:\n",
    "        message = (\n",
    "            f\"Berat sampah Anda ({input_berat_kg} kg) sedikit tidak sesuai dengan rekomendasi \"\n",
    "            f\"untuk kategori ini ({berat_min_kg} kg - {berat_max_kg} kg).\\n\\n\"\n",
    "            \"Namun, berikut adalah beberapa rekomendasi yang bisa diterapkan:\\n\"\n",
    "        )\n",
    "    \n",
    "    return {\n",
    "        \"kategori\": kategori,\n",
    "        \"berat_input_kg\": input_berat_kg,\n",
    "        \"berat_min_kg\": berat_min_kg,\n",
    "        \"berat_max_kg\": berat_max_kg,\n",
    "        \"message\": message,\n",
    "        \"rekomendasi\": rekomendasi_list\n",
    "    }\n",
    "\n",
    "# Simpan model dalam format .keras\n",
    "model.save(\"../models/Sistemrekomendasi/models/recycling_recommendation_model.keras\")\n",
    "print(\"Model berhasil disimpan di folder 'Sistemrekomendasi/models/recycling_recommendation_model.keras'\")\n",
    "\n",
    "# Simpan dataset untuk penggunaan BE/FE\n",
    "df.to_json(\"../models/Sistemrekomendasi/dataset.json\", orient=\"records\", lines=False, force_ascii=False)\n",
    "print(\"Dataset disimpan sebagai 'dataset.json'\")\n",
    "\n",
    "# Setup MLflow\n",
    "MLRUNS_DIR = os.path.abspath(\"../mlruns\")\n",
    "mlflow.set_tracking_uri(f\"file:///{MLRUNS_DIR.replace(os.sep, '/')}\")\n",
    "mlflow.set_experiment(\"Recycling_Recommendation_Experiment\")\n",
    "\n",
    "# Fungsi untuk menyimpan model ke MLflow\n",
    "def save_model_to_mlflow(model, model_name, df, max_tokens):\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Log parameter\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_param(\"max_tokens\", max_tokens)\n",
    "        mlflow.log_param(\"num_entries\", len(df))\n",
    "        mlflow.log_param(\"output_mode\", \"tf_idf\")\n",
    "\n",
    "        # Buat contoh input dan output untuk tanda tangan\n",
    "        sample_input = tf.constant([\"Plastik\"], dtype=tf.string)  # Gunakan tf.constant untuk tipe tf.string\n",
    "        sample_output = model.predict(sample_input)\n",
    "        signature = infer_signature(sample_input.numpy(), sample_output)  # Konversi ke NumPy untuk infer_signature\n",
    "\n",
    "        # Log model ke MLflow\n",
    "        mlflow.keras.log_model(\n",
    "            model=model,\n",
    "            artifact_path=f\"model_{model_name}\",\n",
    "            signature=signature,\n",
    "            registered_model_name=model_name\n",
    "        )\n",
    "\n",
    "        # Log dataset sebagai artefak\n",
    "        dataset_path = \"../models/Sistemrekomendasi/dataset.json\"\n",
    "        mlflow.log_artifact(dataset_path, artifact_path=\"dataset\")\n",
    "\n",
    "        print(f\"Model dan dataset berhasil disimpan ke MLflow di {MLRUNS_DIR}\")\n",
    "\n",
    "# Simpan model ke MLflow\n",
    "try:\n",
    "    save_model_to_mlflow(model, \"Recycling_Recommendation_Model\", df, max_tokens)\n",
    "except Exception as e:\n",
    "    print(f\"Gagal menyimpan model ke MLflow: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd352588",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bayuardiyansyah/anaconda3/envs/tensorflowjs/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Save or restore weights that is not an instance of `tf.Variable` is not supported in h5, use `save_format='tf'` instead. Received a model or layer TextVectorization with weights [<tf.Variable 'Variable:0' shape=(None,) dtype=float32, numpy=\narray([2.623295  , 0.6931472 , 0.99164015, 1.0818052 , 0.94000727,\n       1.2347444 , 1.116004  , 1.0498221 , 1.8827312 , 1.2809339 ,\n       1.3312346 , 1.2809339 , 1.2347444 , 1.770706  , 1.3862944 ,\n       1.3862944 , 1.2347444 , 1.3312346 , 1.3862944 , 1.3862944 ,\n       2.1747518 , 1.5141277 , 1.446919  , 2.3749058 , 1.5141277 ,\n       2.1747518 , 1.5141277 , 1.5141277 , 1.6739764 , 2.1747518 ,\n       1.5892352 , 1.8827312 , 1.5892352 , 1.5892352 , 1.5892352 ,\n       1.8827312 , 2.1747518 , 1.6739764 , 1.8827312 , 1.770706  ,\n       1.8827312 , 1.8827312 , 1.770706  , 2.1747518 , 1.8827312 ,\n       2.014903  , 1.8827312 , 1.8827312 , 1.8827312 , 2.014903  ,\n       2.014903  , 2.014903  , 2.014903  , 2.3749058 , 2.1747518 ,\n       2.1747518 , 2.1747518 , 2.1747518 , 2.3749058 , 2.1747518 ,\n       2.1747518 , 2.1747518 , 2.3749058 , 2.1747518 , 2.1747518 ,\n       2.1747518 , 2.1747518 , 2.3749058 , 2.1747518 , 2.1747518 ,\n       2.1747518 , 2.3749058 , 2.1747518 , 2.6390574 , 2.3749058 ,\n       2.3749058 , 2.3749058 , 2.3749058 , 2.3749058 , 2.3749058 ,\n       2.3749058 , 2.3749058 , 2.3749058 , 2.3749058 , 2.3749058 ,\n       2.3749058 , 2.6390574 , 3.0204248 , 2.6390574 , 2.3749058 ,\n       2.3749058 , 2.6390574 , 2.3749058 , 2.6390574 , 2.6390574 ,\n       2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 ,\n       2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 ,\n       2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 ,\n       2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 ,\n       2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 , 3.0204248 ,\n       2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 ,\n       2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 ,\n       2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 ,\n       2.6390574 , 2.6390574 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 ], dtype=float32)>, <keras.src.layers.preprocessing.index_lookup.VocabWeightHandler object at 0x7f90785be110>, <tf.Variable 'Variable:0' shape=() dtype=int64, numpy=0>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 6. Simpan model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../models/Sistemrekomendasi/models/recycling_recommendation_model.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Simpan dalam format SavedModel\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel berhasil disimpan di folder \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSistemrekomendasi/models/recycling_recommendation_model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflowjs/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflowjs/lib/python3.10/site-packages/keras/src/saving/legacy/hdf5_format.py:1113\u001b[0m, in \u001b[0;36m_legacy_weights\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m   1111\u001b[0m weights \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mtrainable_weights \u001b[38;5;241m+\u001b[39m layer\u001b[38;5;241m.\u001b[39mnon_trainable_weights\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(w, tf\u001b[38;5;241m.\u001b[39mVariable) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m weights):\n\u001b[0;32m-> 1113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSave or restore weights that is not an instance of `tf.Variable` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not supported in h5, use `save_format=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` instead. Received \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1116\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma model or layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1117\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith weights \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweights\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1118\u001b[0m     )\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m weights\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Save or restore weights that is not an instance of `tf.Variable` is not supported in h5, use `save_format='tf'` instead. Received a model or layer TextVectorization with weights [<tf.Variable 'Variable:0' shape=(None,) dtype=float32, numpy=\narray([2.623295  , 0.6931472 , 0.99164015, 1.0818052 , 0.94000727,\n       1.2347444 , 1.116004  , 1.0498221 , 1.8827312 , 1.2809339 ,\n       1.3312346 , 1.2809339 , 1.2347444 , 1.770706  , 1.3862944 ,\n       1.3862944 , 1.2347444 , 1.3312346 , 1.3862944 , 1.3862944 ,\n       2.1747518 , 1.5141277 , 1.446919  , 2.3749058 , 1.5141277 ,\n       2.1747518 , 1.5141277 , 1.5141277 , 1.6739764 , 2.1747518 ,\n       1.5892352 , 1.8827312 , 1.5892352 , 1.5892352 , 1.5892352 ,\n       1.8827312 , 2.1747518 , 1.6739764 , 1.8827312 , 1.770706  ,\n       1.8827312 , 1.8827312 , 1.770706  , 2.1747518 , 1.8827312 ,\n       2.014903  , 1.8827312 , 1.8827312 , 1.8827312 , 2.014903  ,\n       2.014903  , 2.014903  , 2.014903  , 2.3749058 , 2.1747518 ,\n       2.1747518 , 2.1747518 , 2.1747518 , 2.3749058 , 2.1747518 ,\n       2.1747518 , 2.1747518 , 2.3749058 , 2.1747518 , 2.1747518 ,\n       2.1747518 , 2.1747518 , 2.3749058 , 2.1747518 , 2.1747518 ,\n       2.1747518 , 2.3749058 , 2.1747518 , 2.6390574 , 2.3749058 ,\n       2.3749058 , 2.3749058 , 2.3749058 , 2.3749058 , 2.3749058 ,\n       2.3749058 , 2.3749058 , 2.3749058 , 2.3749058 , 2.3749058 ,\n       2.3749058 , 2.6390574 , 3.0204248 , 2.6390574 , 2.3749058 ,\n       2.3749058 , 2.6390574 , 2.3749058 , 2.6390574 , 2.6390574 ,\n       2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 ,\n       2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 ,\n       2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 ,\n       2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 ,\n       2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 , 3.0204248 ,\n       2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 ,\n       2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 ,\n       2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 , 2.6390574 ,\n       2.6390574 , 2.6390574 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 , 3.0204248 ,\n       3.0204248 , 3.0204248 ], dtype=float32)>, <keras.src.layers.preprocessing.index_lookup.VocabWeightHandler object at 0x7f90785be110>, <tf.Variable 'Variable:0' shape=() dtype=int64, numpy=0>]"
     ]
    }
   ],
   "source": [
    "# Simpan model\n",
    "model.save(\"../models/Sistemrekomendasi/models/recycling_recommendation_model.h5\")\n",
    "# Simpan dalam format SavedModel\n",
    "print(\"Model berhasil disimpan di folder 'Sistemrekomendasi/models/recycling_recommendation_model'\")\n",
    "\n",
    "# Simpan dataset untuk penggunaan BE/FE\n",
    "df.to_json(\"../models/Sistemrekomendasi/dataset.json\", orient=\"records\", lines=False, force_ascii=False)\n",
    "print(\"Dataset disimpan sebagai 'dataset.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328f710a",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61b8c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def test_recycling_system():\n",
    "    print(\"======= TESTING SISTEM REKOMENDASI DAUR ULANG =======\")\n",
    "    \n",
    "    # 1. Load Dataset\n",
    "    try:\n",
    "        dataset_path = \"../models/Sistemrekomendasi/dataset.json\"\n",
    "        if not os.path.exists(dataset_path):\n",
    "            print(f\"Dataset tidak ditemukan di path: {dataset_path}\")\n",
    "            print(\"Mencoba mencari di direktori lokal...\")\n",
    "            dataset_path = \"dataset.json\"\n",
    "            \n",
    "            if not os.path.exists(dataset_path):\n",
    "                dataset_path = \"../dataset_rekomendasi_daur_ulang.json\"\n",
    "                if not os.path.exists(dataset_path):\n",
    "                    print(\"Error: Dataset tidak ditemukan. Coba mencari dataset asli...\")\n",
    "                    try:\n",
    "                        with open(\"../dataset_rekomendasi_daur_ulang.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "                            data = json.load(file)\n",
    "                            df = pd.DataFrame(data)\n",
    "                            print(\"Dataset asli berhasil dimuat.\")\n",
    "                    except FileNotFoundError:\n",
    "                        print(\"Error: Semua upaya untuk menemukan dataset gagal.\")\n",
    "                        print(\"Silakan sesuaikan path dataset terlebih dahulu!\")\n",
    "                        return\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(\"Error: Format JSON tidak valid.\")\n",
    "                        return\n",
    "                else:\n",
    "                    print(f\"Dataset ditemukan di: {dataset_path}\")\n",
    "                    df = pd.read_json(dataset_path)\n",
    "            else:\n",
    "                print(f\"Dataset ditemukan di direktori lokal\")\n",
    "                df = pd.read_json(dataset_path)\n",
    "        else:\n",
    "            print(f\"Dataset ditemukan di: {dataset_path}\")\n",
    "            df = pd.read_json(dataset_path)\n",
    "            \n",
    "        print(f\"Total kategori dalam dataset: {len(df['kategori'].unique())}\")\n",
    "        print(f\"Kategori sampah tersedia: {', '.join(df['kategori'].unique())}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error saat memuat dataset: {str(e)}\")\n",
    "        return\n",
    "    \n",
    "    # Cek apakah kolom combined_rekomendasi sudah ada\n",
    "    if 'combined_rekomendasi' not in df.columns:\n",
    "        df['combined_rekomendasi'] = df['rekomendasi'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "\n",
    "    # 2. Load model yang sudah disimpan\n",
    "    print(\"\\nMemuat model vektorisasi teks yang telah disimpan...\")\n",
    "    model_path = \"../models/Sistemrekomendasi/models/recycling_recommendation_model.h5\"\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Error: Model tidak ditemukan di {model_path}\")\n",
    "        return\n",
    "    model = tf.keras.models.load_model(model_path, compile=False)\n",
    "    print(\"Model berhasil dimuat.\")\n",
    "\n",
    "    # 3. Fungsi untuk mendapatkan rekomendasi\n",
    "    def get_recommendation(model, input_kategori, input_berat_kg, df, tolerance=0.2):\n",
    "        matching_rows = df[df['kategori'] == input_kategori]\n",
    "        if matching_rows.empty:\n",
    "            return {\"message\": f\"Kategori '{input_kategori}' tidak ditemukan dalam dataset.\"}\n",
    "    \n",
    "        # Cari indeks baris yang beratnya sesuai\n",
    "        weight_match = matching_rows[\n",
    "            (matching_rows['berat_min_kg'] <= input_berat_kg) &\n",
    "            (input_berat_kg <= matching_rows['berat_max_kg'])\n",
    "        ]\n",
    "    \n",
    "        if not weight_match.empty:\n",
    "            best_match_idx = weight_match.index[0]  # Ambil indeks baris yang sesuai\n",
    "            message = \"\"\n",
    "        else:\n",
    "            best_match_idx = matching_rows.index[0]  # Fallback ke baris pertama\n",
    "            berat_min_kg = matching_rows.loc[best_match_idx]['berat_min_kg']\n",
    "            berat_max_kg = matching_rows.loc[best_match_idx]['berat_max_kg']\n",
    "            message = (\n",
    "                f\"Berat sampah Anda ({input_berat_kg} kg) sedikit tidak sesuai dengan rekomendasi \"\n",
    "                f\"({berat_min_kg} kg - {berat_max_kg} kg).\\n\\n\"\n",
    "                \"Namun, berikut adalah beberapa rekomendasi yang bisa diterapkan:\\n\"\n",
    "            )\n",
    "    \n",
    "        kategori = matching_rows.loc[best_match_idx]['kategori']\n",
    "        rekomendasi_list = matching_rows.loc[best_match_idx]['rekomendasi']\n",
    "        berat_min_kg = matching_rows.loc[best_match_idx]['berat_min_kg']\n",
    "        berat_max_kg = matching_rows.loc[best_match_idx]['berat_max_kg']\n",
    "    \n",
    "        return {\n",
    "            \"kategori\": kategori,\n",
    "            \"berat_input_kg\": input_berat_kg,\n",
    "            \"berat_min_kg\": berat_min_kg,\n",
    "            \"berat_max_kg\": berat_max_kg,\n",
    "            \"message\": message,\n",
    "            \"rekomendasi\": rekomendasi_list\n",
    "        }\n",
    "    \n",
    "\n",
    "    # 4. Jalankan test cases\n",
    "    def run_test_cases(model, df):\n",
    "        available_categories = df['kategori'].unique().tolist()\n",
    "        \n",
    "        test_cases = []\n",
    "        for cat in available_categories:\n",
    "            cat_rows = df[df['kategori'] == cat]\n",
    "            if not cat_rows.empty:\n",
    "                min_weight = cat_rows['berat_min_kg'].values[0]\n",
    "                max_weight = cat_rows['berat_max_kg'].values[0]\n",
    "                \n",
    "                in_range_weight = (min_weight + max_weight) / 2\n",
    "                test_cases.append({\n",
    "                    \"kategori\": cat, \n",
    "                    \"berat\": in_range_weight, \n",
    "                    \"desc\": f\"{cat} dengan berat dalam rentang\"\n",
    "                })\n",
    "                \n",
    "                out_range_weight = max_weight * 2\n",
    "                test_cases.append({\n",
    "                    \"kategori\": cat, \n",
    "                    \"berat\": out_range_weight, \n",
    "                    \"desc\": f\"{cat} dengan berat di luar rentang\"\n",
    "                })\n",
    "        \n",
    "        test_cases.append({\n",
    "            \"kategori\": \"TidakAda\", \n",
    "            \"berat\": 1.0, \n",
    "            \"desc\": \"Kategori yang tidak ada di dataset\"\n",
    "        })\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"HASIL PENGUJIAN DENGAN BERBAGAI KASUS\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        for i, test in enumerate(test_cases, 1):\n",
    "            print(f\"\\nTest Case #{i}: {test['desc']}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            result = get_recommendation(model, test['kategori'], test['berat'], df)\n",
    "            \n",
    "            if \"message\" in result and \"kategori\" not in result:\n",
    "                print(result[\"message\"])\n",
    "                continue\n",
    "                \n",
    "            print(f\"Kategori Sampah: {result['kategori']}\")\n",
    "            print(f\"Berat Sampah: {result['berat_input_kg']} kg (Rentang: {result['berat_min_kg']} kg - {result['berat_max_kg']} kg)\")\n",
    "            \n",
    "            if result['message']:\n",
    "                print(f\"\\n{result['message']}\")\n",
    "                \n",
    "            print(\"Rekomendasi:\")\n",
    "            for idx, ide in enumerate(result['rekomendasi'], 1):\n",
    "                print(f\"{idx}. {ide}\")\n",
    "\n",
    "    # 5. Uji sistem interaktif\n",
    "    def interactive_test():\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"PENGUJIAN INTERAKTIF\")\n",
    "        print(\"=\" * 50)\n",
    "        print(\"Ketik 'exit' untuk keluar dari pengujian interaktif.\")\n",
    "        print(f\"Kategori tersedia: {', '.join(df['kategori'].unique())}\")\n",
    "        \n",
    "        while True:\n",
    "            kategori = input(\"\\nMasukkan kategori sampah: \")\n",
    "            if kategori.lower() == 'exit':\n",
    "                break\n",
    "                \n",
    "            try:\n",
    "                berat = float(input(\"Masukkan berat sampah dalam kg: \"))\n",
    "            except ValueError:\n",
    "                print(\"Error: Berat harus berupa angka. Silakan coba lagi.\")\n",
    "                continue\n",
    "                \n",
    "            result = get_recommendation(model, kategori, berat, df)\n",
    "            \n",
    "            if \"message\" in result and \"kategori\" not in result:\n",
    "                print(result[\"message\"])\n",
    "                continue\n",
    "                \n",
    "            print(\"\\nHasil Rekomendasi:\")\n",
    "            print(f\"Kategori Sampah: {result['kategori']}\")\n",
    "            print(f\"Berat Sampah: {result['berat_input_kg']} kg (Rentang: {result['berat_min_kg']} kg - {result['berat_max_kg']} kg)\")\n",
    "            \n",
    "            if result['message']:\n",
    "                print(f\"\\n{result['message']}\")\n",
    "                \n",
    "            print(\"Rekomendasi:\")\n",
    "            for idx, ide in enumerate(result['rekomendasi'], 1):\n",
    "                print(f\"{idx}. {ide}\")\n",
    "    \n",
    "    # Jalankan semua pengujian\n",
    "    run_test_cases(model, df)\n",
    "    \n",
    "    try_interactive = input(\"\\nApakah Anda ingin mencoba pengujian interaktif? (y/n): \")\n",
    "    if try_interactive.lower() == 'y':\n",
    "        interactive_test()\n",
    "    \n",
    "    print(\"\\n======= PENGUJIAN SELESAI =======\")\n",
    "\n",
    "# Jalankan fungsi\n",
    "if __name__ == \"__main__\":\n",
    "    test_recycling_system()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5337549",
   "metadata": {},
   "source": [
    "### Testing 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf50f1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def test_recycling_system():\n",
    "    print(\"======= TESTING SISTEM REKOMENDASI DAUR ULANG =======\")\n",
    "    \n",
    "    # 1. Load Dataset\n",
    "    try:\n",
    "        dataset_path = \"../models/Sistemrekomendasi/dataset.json\"\n",
    "        if not os.path.exists(dataset_path):\n",
    "            print(f\"Dataset tidak ditemukan di path: {dataset_path}\")\n",
    "            print(\"Mencoba mencari di direktori lokal...\")\n",
    "            dataset_path = \"dataset.json\"\n",
    "            \n",
    "            if not os.path.exists(dataset_path):\n",
    "                dataset_path = \"../dataset_rekomendasi_daur_ulang.json\"\n",
    "                if not os.path.exists(dataset_path):\n",
    "                    print(\"Error: Dataset tidak ditemukan. Coba mencari dataset asli...\")\n",
    "                    try:\n",
    "                        with open(\"../dataset_rekomendasi_daur_ulang.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "                            data = json.load(file)\n",
    "                            df = pd.DataFrame(data)\n",
    "                            print(\"Dataset asli berhasil dimuat.\")\n",
    "                    except FileNotFoundError:\n",
    "                        print(\"Error: Semua upaya untuk menemukan dataset gagal.\")\n",
    "                        print(\"Silakan sesuaikan path dataset terlebih dahulu!\")\n",
    "                        return\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(\"Error: Format JSON tidak valid.\")\n",
    "                        return\n",
    "                else:\n",
    "                    print(f\"Dataset ditemukan di: {dataset_path}\")\n",
    "                    df = pd.read_json(dataset_path)\n",
    "            else:\n",
    "                print(f\"Dataset ditemukan di direktori lokal\")\n",
    "                df = pd.read_json(dataset_path)\n",
    "        else:\n",
    "            print(f\"Dataset ditemukan di: {dataset_path}\")\n",
    "            df = pd.read_json(dataset_path)\n",
    "            \n",
    "        print(f\"Total kategori dalam dataset: {len(df['kategori'].unique())}\")\n",
    "        print(f\"Kategori sampah tersedia: {', '.join(df['kategori'].unique())}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error saat memuat dataset: {str(e)}\")\n",
    "        return\n",
    "    \n",
    "    # Cek apakah kolom combined_rekomendasi sudah ada\n",
    "    if 'combined_rekomendasi' not in df.columns:\n",
    "        df['combined_rekomendasi'] = df['rekomendasi'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "\n",
    "    # 2. Load model yang sudah disimpan\n",
    "    print(\"\\nMemuat model vektorisasi teks yang telah disimpan...\")\n",
    "    model_path = \"../models/Sistemrekomendasi/models/recycling_recommendation_model.h5\"\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Error: Model tidak ditemukan di {model_path}\")\n",
    "        return\n",
    "    model = tf.keras.models.load_model(model_path, compile=False)\n",
    "    print(\"Model berhasil dimuat.\")\n",
    "\n",
    "    # 3. Fungsi untuk mendapatkan rekomendasi\n",
    "    def get_recommendation(model, input_kategori, input_berat_kg, df, tolerance=0.2):\n",
    "        matching_rows = df[df['kategori'] == input_kategori]\n",
    "        if matching_rows.empty:\n",
    "            return {\"message\": f\"Kategori '{input_kategori}' tidak ditemukan dalam dataset.\"}\n",
    "    \n",
    "        # Cari indeks baris yang beratnya sesuai\n",
    "        weight_match = matching_rows[\n",
    "            (matching_rows['berat_min_kg'] <= input_berat_kg) &\n",
    "            (input_berat_kg <= matching_rows['berat_max_kg'])\n",
    "        ]\n",
    "    \n",
    "        if not weight_match.empty:\n",
    "            best_match_idx = weight_match.index[0]  # Ambil indeks baris yang sesuai\n",
    "            message = \"\"\n",
    "        else:\n",
    "            best_match_idx = matching_rows.index[0]  # Fallback ke baris pertama\n",
    "            berat_min_kg = matching_rows.loc[best_match_idx]['berat_min_kg']\n",
    "            berat_max_kg = matching_rows.loc[best_match_idx]['berat_max_kg']\n",
    "            message = (\n",
    "                f\"Berat sampah Anda ({input_berat_kg} kg) sedikit tidak sesuai dengan rekomendasi \"\n",
    "                f\"({berat_min_kg} kg - {berat_max_kg} kg).\\n\\n\"\n",
    "                \"Namun, berikut adalah beberapa rekomendasi yang bisa diterapkan:\\n\"\n",
    "            )\n",
    "    \n",
    "        kategori = matching_rows.loc[best_match_idx]['kategori']\n",
    "        rekomendasi_list = matching_rows.loc[best_match_idx]['rekomendasi']\n",
    "        berat_min_kg = matching_rows.loc[best_match_idx]['berat_min_kg']\n",
    "        berat_max_kg = matching_rows.loc[best_match_idx]['berat_max_kg']\n",
    "    \n",
    "        return {\n",
    "            \"kategori\": kategori,\n",
    "            \"berat_input_kg\": input_berat_kg,\n",
    "            \"berat_min_kg\": berat_min_kg,\n",
    "            \"berat_max_kg\": berat_max_kg,\n",
    "            \"message\": message,\n",
    "            \"rekomendasi\": rekomendasi_list\n",
    "        }\n",
    "    \n",
    "\n",
    "    # 4. Jalankan test cases\n",
    "    def run_test_cases(model, df):\n",
    "        available_categories = df['kategori'].unique().tolist()\n",
    "        \n",
    "        test_cases = []\n",
    "        for cat in available_categories:\n",
    "            cat_rows = df[df['kategori'] == cat]\n",
    "            if not cat_rows.empty:\n",
    "                min_weight = cat_rows['berat_min_kg'].values[0]\n",
    "                max_weight = cat_rows['berat_max_kg'].values[0]\n",
    "                \n",
    "                in_range_weight = (min_weight + max_weight) / 2\n",
    "                test_cases.append({\n",
    "                    \"kategori\": cat, \n",
    "                    \"berat\": in_range_weight, \n",
    "                    \"desc\": f\"{cat} dengan berat dalam rentang\"\n",
    "                })\n",
    "                \n",
    "                out_range_weight = max_weight * 2\n",
    "                test_cases.append({\n",
    "                    \"kategori\": cat, \n",
    "                    \"berat\": out_range_weight, \n",
    "                    \"desc\": f\"{cat} dengan berat di luar rentang\"\n",
    "                })\n",
    "        \n",
    "        test_cases.append({\n",
    "            \"kategori\": \"TidakAda\", \n",
    "            \"berat\": 1.0, \n",
    "            \"desc\": \"Kategori yang tidak ada di dataset\"\n",
    "        })\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"HASIL PENGUJIAN DENGAN BERBAGAI KASUS\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        for i, test in enumerate(test_cases, 1):\n",
    "            print(f\"\\nTest Case #{i}: {test['desc']}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            result = get_recommendation(model, test['kategori'], test['berat'], df)\n",
    "            \n",
    "            if \"message\" in result and \"kategori\" not in result:\n",
    "                print(result[\"message\"])\n",
    "                continue\n",
    "                \n",
    "            print(f\"Kategori Sampah: {result['kategori']}\")\n",
    "            print(f\"Berat Sampah: {result['berat_input_kg']} kg (Rentang: {result['berat_min_kg']} kg - {result['berat_max_kg']} kg)\")\n",
    "            \n",
    "            if result['message']:\n",
    "                print(f\"\\n{result['message']}\")\n",
    "                \n",
    "            print(\"Rekomendasi:\")\n",
    "            for idx, ide in enumerate(result['rekomendasi'], 1):\n",
    "                print(f\"{idx}. {ide}\")\n",
    "\n",
    "    # 5. Uji sistem interaktif\n",
    "    def interactive_test():\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"PENGUJIAN INTERAKTIF\")\n",
    "        print(\"=\" * 50)\n",
    "        print(\"Ketik 'exit' untuk keluar dari pengujian interaktif.\")\n",
    "        print(f\"Kategori tersedia: {', '.join(df['kategori'].unique())}\")\n",
    "        \n",
    "        while True:\n",
    "            kategori = input(\"\\nMasukkan kategori sampah: \")\n",
    "            if kategori.lower() == 'exit':\n",
    "                break\n",
    "                \n",
    "            try:\n",
    "                berat = float(input(\"Masukkan berat sampah dalam kg: \"))\n",
    "            except ValueError:\n",
    "                print(\"Error: Berat harus berupa angka. Silakan coba lagi.\")\n",
    "                continue\n",
    "                \n",
    "            result = get_recommendation(model, kategori, berat, df)\n",
    "            \n",
    "            if \"message\" in result and \"kategori\" not in result:\n",
    "                print(result[\"message\"])\n",
    "                continue\n",
    "                \n",
    "            print(\"\\nHasil Rekomendasi:\")\n",
    "            print(f\"Kategori Sampah: {result['kategori']}\")\n",
    "            print(f\"Berat Sampah: {result['berat_input_kg']} kg (Rentang: {result['berat_min_kg']} kg - {result['berat_max_kg']} kg)\")\n",
    "            \n",
    "            if result['message']:\n",
    "                print(f\"\\n{result['message']}\")\n",
    "                \n",
    "            print(\"Rekomendasi:\")\n",
    "            for idx, ide in enumerate(result['rekomendasi'], 1):\n",
    "                print(f\"{idx}. {ide}\")\n",
    "    \n",
    "    # Jalankan semua pengujian\n",
    "    run_test_cases(model, df)\n",
    "    \n",
    "    try_interactive = input(\"\\nApakah Anda ingin mencoba pengujian interaktif? (y/n): \")\n",
    "    if try_interactive.lower() == 'y':\n",
    "        interactive_test()\n",
    "    \n",
    "    print(\"\\n======= PENGUJIAN SELESAI =======\")\n",
    "\n",
    "# Jalankan fungsi\n",
    "if __name__ == \"__main__\":\n",
    "    test_recycling_system()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowjs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
